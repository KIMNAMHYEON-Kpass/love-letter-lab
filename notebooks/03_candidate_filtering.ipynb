{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNifVDYFoc2sQX5Ot3xC0mK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KIMNAMHYEON-Kpass/love-letter-lab/blob/main/notebooks/03_candidate_filtering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 설치 및 환경설정"
      ],
      "metadata": {
        "id": "8WIfvA2QqJng"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r3Sx6umphRs"
      },
      "outputs": [],
      "source": [
        "# 설치\n",
        "!pip install -q transformers accelerate sentencepiece datasets\n",
        "\n",
        "# 임포트\n",
        "import os, json, random, math, re\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# 재현성\n",
        "random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# 경로 준비\n",
        "DATA_DIR = Path(\"data\")\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "RAW_PATH = DATA_DIR/\"candidates_raw.json\"\n",
        "FILTERED_PATH = DATA_DIR/\"candidates_filtered.json\"\n",
        "\n",
        "print({\"data_dir\": str(DATA_DIR), \"raw\": str(RAW_PATH), \"filtered\": str(FILTERED_PATH)})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 모델 로드"
      ],
      "metadata": {
        "id": "mSCuugNcqBEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 한국어 감성/정서 분류 모델 예시 (모델은 상황에 맞게 교체 가능)\n",
        "MODEL_NAME = \"beomi/KcELECTRA-base\"  # 예시: 토크나이저 용도로 불러와도 됨\n",
        "\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    # 감성 분류용 헤드가 포함된 모델로 교체 필요\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    print({\"model_loaded\": MODEL_NAME, \"device\": device})\n",
        "except Exception as e:\n",
        "    print(\"모델 로딩 경고:\", e)\n",
        "    print(\"실제 감성분류 체크포인트로 교체해 주세요. (수업 모델/실습 모델 권장)\")\n",
        "    tokenizer = None\n",
        "    model = None"
      ],
      "metadata": {
        "id": "d3oASQ8opsUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 후보 생성"
      ],
      "metadata": {
        "id": "avY8gBdXqDnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데모용: 규칙/템플릿 기반 후보(10~20개) 생성\n",
        "# 이후 LLM으로 대체할 때 이 함수만 교체하세요.\n",
        "def generate_candidates_demo(name: str, relation: str, situation: str, tone: str, n: int = 20) -> List[str]:\n",
        "    # 간단 템플릿과 어휘 풀(프로젝트 합의에 맞게 보강 가능)\n",
        "    tone_words = {\n",
        "        \"달달\": [\"따뜻하게\", \"사근사근하게\", \"조심스럽게\", \"포근하게\"],\n",
        "        \"시풍\": [\"은근히\", \"고즈넉히\", \"담담하게\", \"단정히\"],\n",
        "        \"재치\": [\"가볍게\", \"살짝\", \"은근슬쩍\", \"재치있게\"]\n",
        "    }\n",
        "    style = tone_words.get(tone, [\"자연스럽게\"])\n",
        "\n",
        "    seeds = [\n",
        "        f\"{name}님, {situation} 속에서도 마음이 자꾸 {relation}로서 더 가까워지고 싶어집니다.\",\n",
        "        f\"{name}님, {relation}로 지내며 알게 된 소중함을 {random.choice(style)} 전하고 싶어요.\",\n",
        "        f\"{name}님께 조심스럽게 말해봅니다. {situation} 같은 순간에도 곁에서 응원하고 싶어요.\",\n",
        "        f\"{name}님, 무리하지 않으셨으면 해요. {relation}로서 제가 옆에 있겠습니다.\",\n",
        "        f\"{name}님과 조금 더 자주, {random.choice(['커피 한 잔','산책','짧은 대화'])}을 나누고 싶습니다.\"\n",
        "    ]\n",
        "    out = []\n",
        "    for _ in range(n):\n",
        "        s = random.choice(seeds)\n",
        "        # 가벼운 변형\n",
        "        s2 = s.replace(\"싶어집니다\", random.choice([\"바랍니다\",\"원합니다\",\"바라게 됩니다\"]))\n",
        "        if random.random() < 0.3:\n",
        "            s2 += \" 제 마음이 부담이 되지 않았으면 합니다.\"\n",
        "        if random.random() < 0.3:\n",
        "            s2 = s2.replace(\"응원하고 싶어요\", \"응원하고 싶습니다\")\n",
        "        out.append(s2)\n",
        "    return out\n",
        "\n",
        "# 예시 입력\n",
        "name = \"민수\"\n",
        "relation = \"동기\"\n",
        "situation = \"발표를 앞두고 긴장한 상황\"\n",
        "tone = \"달달\"\n",
        "\n",
        "candidates_raw = generate_candidates_demo(name, relation, situation, tone, n=24)\n",
        "print({\"generated\": len(candidates_raw)})\n",
        "for i, c in enumerate(candidates_raw[:5], 1):\n",
        "    print(f\"{i:02d}. {c}\")"
      ],
      "metadata": {
        "id": "Ad5vXiaapo-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 규칙 기반 필터링"
      ],
      "metadata": {
        "id": "OBC6H4aUqHI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 금칙(예시): 프로젝트 팀 합의에 따라 자유롭게 변경\n",
        "PROFANITIES = [\n",
        "    \"씨발\",\"좆\",\"병신\",\"꺼져\",\"등신\",\"죽어\",\"지랄\",\"sex\",\"섹스\",\"야한\",\"폭력\",\"협박\"\n",
        "]\n",
        "# 과도한 사적인 추정/민감 표현 샘플\n",
        "SENSITIVE = [\n",
        "    \"주민번호\",\"주소\",\"연봉\",\"계좌\",\"카드번호\",\"숙박\",\"만나자호텔\"\n",
        "]\n",
        "\n",
        "# 형식 규칙\n",
        "MAX_EXCLAIMS = 1    # 느낌표 최대 1회\n",
        "ALLOW_EMOJI = False # 이모지 금지\n",
        "MAX_LEN = 160       # 후보 문구 최대 길이(문자 기준) - 필요 시 조정\n",
        "MIN_LEN = 20        # 최소 길이(너무 짧은 문구 제거 목적)\n",
        "\n",
        "EMOJI_PATTERN = re.compile(r\"[\\U0001F600-\\U0001F64F\"\n",
        "                           r\"\\U0001F300-\\U0001F5FF\"\n",
        "                           r\"\\U0001F680-\\U0001F6FF\"\n",
        "                           r\"\\U0001F1E0-\\U0001F1FF]+\", flags=re.UNICODE)\n",
        "\n",
        "def contains_emoji(text: str) -> bool:\n",
        "    return EMOJI_PATTERN.search(text) is not None\n",
        "\n",
        "def count_exclaims(text: str) -> int:\n",
        "    return text.count(\"!\")\n",
        "\n",
        "def rule_checks(text: str) -> Dict[str, Any]:\n",
        "    reasons = []\n",
        "    ok = True\n",
        "\n",
        "    # 길이\n",
        "    if not (MIN_LEN <= len(text) <= MAX_LEN):\n",
        "        ok = False\n",
        "        reasons.append({\"rule\":\"length\", \"value\":len(text), \"min\":MIN_LEN, \"max\":MAX_LEN})\n",
        "\n",
        "    # 이모지\n",
        "    if not ALLOW_EMOJI and contains_emoji(text):\n",
        "        ok = False\n",
        "        reasons.append({\"rule\":\"emoji\", \"value\":\"found\"})\n",
        "\n",
        "    # 느낌표\n",
        "    ex_cnt = count_exclaims(text)\n",
        "    if ex_cnt > MAX_EXCLAIMS:\n",
        "        ok = False\n",
        "        reasons.append({\"rule\":\"exclaim_limit\", \"value\":ex_cnt, \"max\":MAX_EXCLAIMS})\n",
        "\n",
        "    # 금칙\n",
        "    prof_hits = [w for w in PROFANITIES if w in text]\n",
        "    sens_hits = [w for w in SENSITIVE if w in text]\n",
        "    if prof_hits:\n",
        "        ok = False\n",
        "        reasons.append({\"rule\":\"profanity\", \"hits\":prof_hits})\n",
        "    if sens_hits:\n",
        "        ok = False\n",
        "        reasons.append({\"rule\":\"sensitive\", \"hits\":sens_hits})\n",
        "\n",
        "    return {\"ok\": ok, \"reasons\": reasons}"
      ],
      "metadata": {
        "id": "rVQxpldhpnF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 감성 필터링"
      ],
      "metadata": {
        "id": "3J1Jp88vp95-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 아키텍처/라벨 매핑에 따라 점수 계산이 달라집니다.\n",
        "def get_sentiment_score(text: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    데모용 점수: 모델이 제대로 로딩되지 않으면 간단 휴리스틱으로 대체.\n",
        "    \"\"\"\n",
        "    if tokenizer is None or model is None:\n",
        "        # 휴리스틱 백업(긍부정 어휘 기반)\n",
        "        pos_words = [\"좋\", \"고맙\", \"따뜻\", \"응원\", \"함께\", \"설렘\", \"안심\", \"행복\"]\n",
        "        neg_words = [\"미안\", \"불안\", \"걱정\", \"슬픔\", \"외로움\", \"싫\", \"후회\"]\n",
        "        pos = sum(w in text for w in pos_words)\n",
        "        neg = sum(w in text for w in neg_words)\n",
        "        total = max(1, pos+neg)\n",
        "        score_pos = pos/total\n",
        "        score_neg = neg/total\n",
        "        label = \"pos\" if score_pos >= score_neg else \"neg\"\n",
        "        return {\"score_pos\": float(score_pos), \"score_neg\": float(score_neg), \"label\": label, \"mode\": \"heuristic\"}\n",
        "    else:\n",
        "        with torch.no_grad():\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=256).to(model.device)\n",
        "            logits = model(**inputs).logits\n",
        "            probs = torch.softmax(logits, dim=-1).squeeze().tolist()\n",
        "            # 라벨 인덱스 매핑은 실제 모델 카드 문서 참고 필요\n",
        "            if len(probs) == 2:\n",
        "                score_neg, score_pos = probs[0], probs[1]\n",
        "            else:\n",
        "                score_pos = float(max(probs))\n",
        "                score_neg = float(min(probs))\n",
        "            label = \"pos\" if score_pos >= score_neg else \"neg\"\n",
        "            return {\"score_pos\": float(score_pos), \"score_neg\": float(score_neg), \"label\": label, \"mode\": \"model\"}\n"
      ],
      "metadata": {
        "id": "AvjIfbDNpu5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. 통과/탈락 분류"
      ],
      "metadata": {
        "id": "6EdKNj7Pp7OV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_candidate(text: str) -> Dict[str, Any]:\n",
        "    rules = rule_checks(text)\n",
        "    senti = get_sentiment_score(text)\n",
        "\n",
        "    # 간단 통과 기준(예시): 규칙 통과 & 긍정 점수 >= 0.5\n",
        "    passed = rules[\"ok\"] and (senti[\"score_pos\"] >= 0.5)\n",
        "\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"passed\": passed,\n",
        "        \"rules\": rules,\n",
        "        \"sentiment\": senti\n",
        "    }\n",
        "\n",
        "evaluated = [evaluate_candidate(t) for t in candidates_raw]\n",
        "passed_items = [e for e in evaluated if e[\"passed\"]]\n",
        "failed_items = [e for e in evaluated if not e[\"passed\"]]\n",
        "\n",
        "print({\"total\": len(evaluated), \"passed\": len(passed_items), \"failed\": len(failed_items)})\n",
        "for i, e in enumerate(passed_items[:5], 1):\n",
        "    print(f\"{i:02d}. {e['text']}  | pos={e['sentiment']['score_pos']:.2f}\")"
      ],
      "metadata": {
        "id": "Km4PiD7CpwzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. JSON 저장"
      ],
      "metadata": {
        "id": "CMNyntxAp4mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 원본 후보 저장\n",
        "raw_payload = {\n",
        "    \"meta\": {\"name\": name, \"relation\": relation, \"situation\": situation, \"tone\": tone},\n",
        "    \"candidates\": candidates_raw\n",
        "}\n",
        "with open(RAW_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(raw_payload, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# 필터 결과 저장\n",
        "filtered_payload = {\n",
        "    \"meta\": {\"name\": name, \"relation\": relation, \"situation\": situation, \"tone\": tone},\n",
        "    \"selected\": passed_items,\n",
        "    \"rejected\": failed_items[:10]\n",
        "}\n",
        "with open(FILTERED_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(filtered_payload, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print({\"saved_raw\": str(RAW_PATH), \"saved_filtered\": str(FILTERED_PATH)})"
      ],
      "metadata": {
        "id": "BCy7H7BhpyhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. 검증"
      ],
      "metadata": {
        "id": "q9DCyf1zp16e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 노트북 자체 검증: 파일 존재 여부, 통과 항목≥1 여부를 딕셔너리로 print\n",
        "print({\n",
        "    \"file_exists\": FILTERED_PATH.exists(),\n",
        "    \"passed_items_gt_1\": len(passed_items) >= 1,\n",
        "})"
      ],
      "metadata": {
        "id": "DI69CFrcp1FV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}