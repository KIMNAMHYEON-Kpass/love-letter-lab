{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/KIMNAMHYEON-Kpass/love-letter-lab/blob/main/notebooks/02_scoring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro-description-cell"
   },
   "source": [
    "## 노트북 개요: 퍼스널리티 기반 연애편지 채점기\\n이 노트북은 주어진 텍스트(연애 편지)에 대해 설정된 퍼스널리티에 따라 호감도 점수를 계산하고 분석하는 과정을 담고 있습니다. 주요 기능은 다음과 같습니다:\\n- JSON 파일로부터 퍼스널리티 프리셋과 채점 규칙 로드\\n- 텍스트의 긍정/부정/금칙어, 존댓말 사용 비율, 반복성 등을 분석하는 기본 점수화\\n- 설정된 퍼스널리티(예: '정중·낭만', '직설·건조')와의 일치도에 따른 보너스 점수 부여\\n- 최종 호감도 점수(0~1)와 채점 근거 산출\\n- 샘플 데이터 실행 및 결과 캐시 저장\\n- 간단한 품질 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVM-JFJAFDIh"
   },
   "source": [
    "# 1. 설치 및 환경 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T07:35:33.332822Z",
     "iopub.status.busy": "2025-08-18T07:35:33.331920Z",
     "iopub.status.idle": "2025-08-18T07:35:52.635815Z",
     "shell.execute_reply": "2025-08-18T07:35:52.634536Z"
    },
    "id": "bJvDdpmLFAhQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_dir': 'data', 'config_dir': 'config'}\n"
     ]
    }
   ],
   "source": [
    "# (필요시) 경량 설치\n",
    "!pip install -q numpy pandas\n",
    "\n",
    "import math, json, re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "CONFIG_DIR = Path(\"config\")\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CONFIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print({\"data_dir\": str(DATA_DIR), \"config_dir\": str(CONFIG_DIR)})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Er4T9lJGFHph"
   },
   "source": [
    "# 퍼스널리티 프리셋/규칙 로딩(없으면 기본 생성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T07:35:52.640611Z",
     "iopub.status.busy": "2025-08-18T07:35:52.640117Z",
     "iopub.status.idle": "2025-08-18T07:35:52.652689Z",
     "shell.execute_reply": "2025-08-18T07:35:52.651486Z"
    },
    "id": "CV7BRafGFLNO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'presets': ['정중·낭만', '직설·건조', '재치·가벼움'], 'rules_loaded': True}\n"
     ]
    }
   ],
   "source": [
    "# 기본 프리셋\n",
    "default_presets = {\n",
    "    \"정중·낭만\": {\n",
    "        \"humor\":0.2, \"directness\":0.3, \"formality\":0.9,\n",
    "        \"emotion_intensity\":0.7, \"metaphor\":0.8, \"sincerity\":0.9\n",
    "    },\n",
    "    \"직설·건조\": {\n",
    "        \"humor\":0.1, \"directness\":0.9, \"formality\":0.6,\n",
    "        \"emotion_intensity\":0.3, \"metaphor\":0.2, \"sincerity\":0.7\n",
    "    },\n",
    "    \"재치·가벼움\": {\n",
    "        \"humor\":0.8, \"directness\":0.5, \"formality\":0.4,\n",
    "        \"emotion_intensity\":0.6, \"metaphor\":0.6, \"sincerity\":0.5\n",
    "    }\n",
    "}\n",
    "\n",
    "# 기본 규칙(금칙/긍·부정 어휘/비유·유머 키워드)\n",
    "rules = {\n",
    "    \"profanity\": [\"씨발\",\"좆\",\"병신\",\"꺼져\",\"등신\",\"죽어\",\"지랄\",\"sex\",\"섹스\",\"야한\",\"폭력\",\"협박\"],\n",
    "    \"positive\": [\"좋\",\"고맙\",\"따뜻\",\"응원\",\"함께\",\"설렘\",\"안심\",\"행복\",\"사랑\",\"배려\",\"고마움\",\"기쁨\"],\n",
    "    \"negative\": [\"미안\",\"불안\",\"걱정\",\"슬픔\",\"후회\",\"외로움\",\"싫\",\"두려움\",\"불편\",\"짜증\"],\n",
    "    \"metaphor\": [\"별\",\"달\",\"계절\",\"바람\",\"파도\",\"편지\",\"햇살\",\"꽃\"],\n",
    "    \"humor\": [\"농담\",\"웃음\",\"장난\",\"살짝\",\"가볍게\"]\n",
    "}\n",
    "\n",
    "# 파일로부터 로딩 시도(없으면 기본 저장)\n",
    "ppath = CONFIG_DIR/\"personality_presets.json\"\n",
    "rpath = CONFIG_DIR/\"reason_rules.json\"\n",
    "\n",
    "if ppath.exists():\n",
    "    personality_presets = json.loads(ppath.read_text(encoding=\"utf-8\"))\n",
    "else:\n",
    "    ppath.write_text(json.dumps(default_presets, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    personality_presets = default_presets\n",
    "\n",
    "if rpath.exists():\n",
    "    reason_rules = json.loads(rpath.read_text(encoding=\"utf-8\"))\n",
    "else:\n",
    "    rpath.write_text(json.dumps(rules, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "    reason_rules = rules\n",
    "\n",
    "print({\"presets\": list(personality_presets.keys()), \"rules_loaded\": True})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmnkvafyFMxR"
   },
   "source": [
    "# 기본 점수화 함수들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T07:35:52.656042Z",
     "iopub.status.busy": "2025-08-18T07:35:52.655716Z",
     "iopub.status.idle": "2025-08-18T07:35:52.664525Z",
     "shell.execute_reply": "2025-08-18T07:35:52.663155Z"
    },
    "id": "TvJN8cY7FPtG"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x: float) -> float:\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "\n",
    "def count_hits(text: str, keywords):\n",
    "    return sum(1 for w in keywords if w in text)\n",
    "\n",
    "def is_respectful_korean(text: str) -> float:\n",
    "    # 존댓말 비율 근사치: '요', '습니다' 빈도 기반\n",
    "    toks = re.split(r\"\\s+\", text)\n",
    "    if not toks:\n",
    "        return 0.0\n",
    "    hits = sum(1 for t in toks if (\"요\" in t or \"습니다\" in t))\n",
    "    return hits / max(1, len(toks))\n",
    "\n",
    "def repetition_penalty(text: str, n: int = 3) -> float:\n",
    "    # 간단 n-gram 반복률 측정(근사)\n",
    "    words = re.findall(r\"\\w+|[가-힣]+\", text)\n",
    "    if len(words) < n:\n",
    "        return 0.0\n",
    "    grams = [\" \".join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "    total = len(grams)\n",
    "    unique = len(set(grams))\n",
    "    dup_ratio = 1 - unique/max(1,total)\n",
    "    return dup_ratio  # 0~1, 높을수록 반복 많음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQOw_GWyFRaE"
   },
   "source": [
    "# 호감도 점수 산출 로직"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T07:35:52.668385Z",
     "iopub.status.busy": "2025-08-18T07:35:52.668014Z",
     "iopub.status.idle": "2025-08-18T07:35:52.685876Z",
     "shell.execute_reply": "2025-08-18T07:35:52.684229Z"
    },
    "id": "cR3Y1u8OFTyc"
   },
   "outputs": [],
   "source": [
    "def base_sentiment_score(text: str, rule_dict: dict) -> (float, list):\n",
    "    pos_c = count_hits(text, rule_dict[\"positive\"])\n",
    "    neg_c = count_hits(text, rule_dict[\"negative\"])\n",
    "    prof_c = count_hits(text, rule_dict[\"profanity\"])\n",
    "\n",
    "    # 기본 감정 합산\n",
    "    raw = pos_c*0.6 - neg_c*0.6 - prof_c*2.0\n",
    "\n",
    "    # 존댓말/느낌표/반복 등 가벼운 보정\n",
    "    form_ratio = is_respectful_korean(text)\n",
    "    raw += (form_ratio - 0.5) * 0.6  # 존댓말 비율이 0.5보다 높으면 가점\n",
    "\n",
    "    exclaims = text.count(\"!\")\n",
    "    if exclaims > 1:\n",
    "        raw -= 0.2*(exclaims-1)\n",
    "\n",
    "    dup = repetition_penalty(text, n=3)\n",
    "    if dup > 0.15:\n",
    "        raw -= 0.3\n",
    "\n",
    "    reasons = [\n",
    "        {\"rule\":\"positive_words\",\"count\":pos_c,\"weight\":0.6},\n",
    "        {\"rule\":\"negative_words\",\"count\":neg_c,\"weight\":-0.6},\n",
    "        {\"rule\":\"profanity\",\"count\":prof_c,\"weight\":-2.0},\n",
    "        {\"rule\":\"formality_ratio\",\"value\":round(form_ratio,2),\"weight\":0.6},\n",
    "        {\"rule\":\"exclaim_count\",\"value\":exclaims,\"penalty_per_extra\":-0.2},\n",
    "        {\"rule\":\"repetition_3gram\",\"value\":round(dup,2),\"threshold\":0.15,\"penalty\":-0.3},\n",
    "    ]\n",
    "    return raw, reasons\n",
    "\n",
    "def personality_bonus(text: str, persona: dict, rule_dict: dict) -> (float, list):\n",
    "    bonus = 0.0\n",
    "    logs = []\n",
    "\n",
    "    # 형식 일치\n",
    "    form_ratio = is_respectful_korean(text)\n",
    "    if persona.get(\"formality\",0) > 0.7 and form_ratio > 0.8:\n",
    "        bonus += 0.3\n",
    "        logs.append({\"rule\":\"formality_match\",\"delta\":0.3})\n",
    "\n",
    "    # 직설성: 의사 표현 키워드 간단 체크\n",
    "    direct_markers = [\"말해볼게요\",\"전하고 싶\",\"원합니다\",\"허락\",\"바랍니다\",\"고백\"]\n",
    "    if persona.get(\"directness\",0) > 0.7 and any(m in text for m in direct_markers):\n",
    "        bonus += 0.2\n",
    "        logs.append({\"rule\":\"directness_match\",\"delta\":0.2})\n",
    "\n",
    "    # 비유 선호\n",
    "    if persona.get(\"metaphor\",0) > 0.6 and count_hits(text, rule_dict[\"metaphor\"]) >= 1:\n",
    "        bonus += 0.2\n",
    "        logs.append({\"rule\":\"metaphor_hit\",\"delta\":0.2})\n",
    "\n",
    "    # 유머 선호\n",
    "    if persona.get(\"humor\",0) > 0.6 and count_hits(text, rule_dict[\"humor\"]) >= 1:\n",
    "        bonus += 0.2\n",
    "        logs.append({\"rule\":\"humor_hit\",\"delta\":0.2})\n",
    "\n",
    "    # 진정성: 과장어휘 과다 시 페널티(진정성 높을수록 과장 싫어함)\n",
    "    over_claims = [\"최고\",\"영원\",\"완벽\",\"운명\",\"세상에 하나\"]\n",
    "    if persona.get(\"sincerity\",0) > 0.7 and sum(1 for w in over_claims if w in text) >= 2:\n",
    "        bonus -= 0.2\n",
    "        logs.append({\"rule\":\"overclaim_penalty\",\"delta\":-0.2})\n",
    "\n",
    "    return bonus, logs\n",
    "\n",
    "def affinity_score(text: str, persona_name: str) -> dict:\n",
    "    persona = personality_presets.get(persona_name, list(personality_presets.values())[0])\n",
    "    base_raw, base_logs = base_sentiment_score(text, reason_rules)\n",
    "    p_bonus, p_logs = personality_bonus(text, persona, reason_rules)\n",
    "\n",
    "    raw = base_raw + p_bonus\n",
    "    score = sigmoid(raw)  # 0~1\n",
    "    reasons = base_logs + p_logs + [{\"rule\":\"total_raw\",\"value\":round(raw,3)}]\n",
    "    return {\n",
    "        \"score_0_1\": round(float(score), 4),\n",
    "        \"raw\": round(float(raw), 3),\n",
    "        \"persona\": {\"name\": persona_name, \"vector\": persona},\n",
    "        \"reasons\": reasons\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5zqqqGxSFXqd"
   },
   "source": [
    "# 샘플 입력과 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T07:35:52.690052Z",
     "iopub.status.busy": "2025-08-18T07:35:52.689699Z",
     "iopub.status.idle": "2025-08-18T07:35:52.718016Z",
     "shell.execute_reply": "2025-08-18T07:35:52.716871Z"
    },
    "id": "-fxYnx6KFZxV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persona</th>\n",
       "      <th>score</th>\n",
       "      <th>raw</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>정중·낭만</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.995</td>\n",
       "      <td>민수님, 발표를 앞두고 긴장하셨겠지만 저는 곁에서 조용히 응원하고 싶습니다. 동기로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>직설·건조</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.020</td>\n",
       "      <td>민수님, 솔직하게 말할게요. 저는 더 가까워지고 싶습니다. 부담되지 않는 선에서 시...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>재치·가벼움</td>\n",
       "      <td>0.495</td>\n",
       "      <td>-0.020</td>\n",
       "      <td>민수님, 너무 과장하진 않을게요. 그냥 같이 커피 한 잔 하면서 가볍게 이야기 나눌...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  persona  score    raw                                               text\n",
       "0   정중·낭만  0.730  0.995  민수님, 발표를 앞두고 긴장하셨겠지만 저는 곁에서 조용히 응원하고 싶습니다. 동기로...\n",
       "2   직설·건조  0.505  0.020  민수님, 솔직하게 말할게요. 저는 더 가까워지고 싶습니다. 부담되지 않는 선에서 시...\n",
       "1  재치·가벼움  0.495 -0.020  민수님, 너무 과장하진 않을게요. 그냥 같이 커피 한 잔 하면서 가볍게 이야기 나눌..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = [\n",
    "    {\n",
    "        \"text\": \"민수님, 발표를 앞두고 긴장하셨겠지만 저는 곁에서 조용히 응원하고 싶습니다. 동기로 지내며 알게 된 고마움이 커졌습니다. 조심스럽지만 제 마음을 말해볼게요.\",\n",
    "        \"persona\":\"정중·낭만\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"민수님, 너무 과장하진 않을게요. 그냥 같이 커피 한 잔 하면서 가볍게 이야기 나눌 수 있을까요?\",\n",
    "        \"persona\":\"재치·가벼움\"\n",
    "    },\n",
    "    {\n",
    "        \"text\": \"민수님, 솔직하게 말할게요. 저는 더 가까워지고 싶습니다. 부담되지 않는 선에서 시간을 허락해 주실 수 있을까요!\",\n",
    "        \"persona\":\"직설·건조\"\n",
    "    }\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for s in samples:\n",
    "    out = affinity_score(s[\"text\"], s[\"persona\"])\n",
    "    rows.append({\n",
    "        \"persona\": s[\"persona\"],\n",
    "        \"score\": out[\"score_0_1\"],\n",
    "        \"raw\": out[\"raw\"],\n",
    "        \"text\": s[\"text\"][:60] + (\"...\" if len(s[\"text\"])>60 else \"\")\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows).sort_values(\"score\", ascending=False)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXdGRPPhFcvn"
   },
   "source": [
    "# 단일 입력용 유틸(노트북에서 바로 써보기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T07:35:52.722036Z",
     "iopub.status.busy": "2025-08-18T07:35:52.721589Z",
     "iopub.status.idle": "2025-08-18T07:35:52.730355Z",
     "shell.execute_reply": "2025-08-18T07:35:52.729163Z"
    },
    "id": "MI8vc-Q7Fd4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[persona] 정중·낭만\n",
      "[score] 0.5907 (raw=0.367)\n",
      "[reasons]\n",
      " - {'rule': 'positive_words', 'count': 1, 'weight': 0.6}\n",
      " - {'rule': 'negative_words', 'count': 0, 'weight': -0.6}\n",
      " - {'rule': 'profanity', 'count': 0, 'weight': -2.0}\n",
      " - {'rule': 'formality_ratio', 'value': 0.11, 'weight': 0.6}\n",
      " - {'rule': 'exclaim_count', 'value': 0, 'penalty_per_extra': -0.2}\n",
      " - {'rule': 'repetition_3gram', 'value': 0.0, 'threshold': 0.15, 'penalty': -0.3}\n",
      " - {'rule': 'total_raw', 'value': 0.367}\n"
     ]
    }
   ],
   "source": [
    "def score_one(text: str, persona_name: str = \"정중·낭만\", verbose: bool = True):\n",
    "    out = affinity_score(text, persona_name)\n",
    "    if verbose:\n",
    "        print(f\"[persona] {persona_name}\")\n",
    "        print(f\"[score] {out['score_0_1']} (raw={out['raw']})\")\n",
    "        print(\"[reasons]\")\n",
    "        for r in out[\"reasons\"]:\n",
    "            print(\" -\", r)\n",
    "    return out\n",
    "\n",
    "# 예시 실행\n",
    "_ = score_one(\"민수님, 떨리는 마음이지만 진심으로 더 자주 함께 걷고 싶습니다.\", \"정중·낭만\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBX1Nb5DFhaP"
   },
   "source": [
    "# 결과 저장(샘플/캐시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T07:35:52.733614Z",
     "iopub.status.busy": "2025-08-18T07:35:52.733181Z",
     "iopub.status.idle": "2025-08-18T07:35:52.741964Z",
     "shell.execute_reply": "2025-08-18T07:35:52.740696Z"
    },
    "id": "gNPuVzJDFfay"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: data/scoring_cache.json\n"
     ]
    }
   ],
   "source": [
    "cache = {\n",
    "    \"samples\": samples,\n",
    "    \"results\": [affinity_score(s[\"text\"], s[\"persona\"]) for s in samples]\n",
    "}\n",
    "(DATA_DIR/\"scoring_cache.json\").write_text(json.dumps(cache, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "print(\"saved:\", str(DATA_DIR/\"scoring_cache.json\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX6cuE9uFkTX"
   },
   "source": [
    "# 검증 셀(노트북 품질 체크)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-18T07:35:52.745114Z",
     "iopub.status.busy": "2025-08-18T07:35:52.744809Z",
     "iopub.status.idle": "2025-08-18T07:35:52.754067Z",
     "shell.execute_reply": "2025-08-18T07:35:52.752979Z"
    },
    "id": "LKSLdKNIFmuQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 검증 결과 ---\n",
      "점수 범위 정상 (0~1): True\n",
      "최소 근거 개수 충족 (>=2): True\n",
      "금칙어 없음: True\n",
      "\n",
      "==> 최종 품질 검증: 통과\n"
     ]
    }
   ],
   "source": [
    "# 검증: 캐시된 결과가 품질 기준을 만족하는지 확인\n",
    "# 기준: 0<=score<=1, reasons>=2, profanity=0\n",
    "\n",
    "def profanity_hits(text: str) -> int:\n",
    "    # 금칙어 포함 여부만 간단히 확인하는 함수\n",
    "    return count_hits(text, reason_rules.get(\"profanity\", []))\n",
    "\n",
    "# 1. 점수(score)가 0과 1 사이인지 확인\n",
    "ok_range = all(0.0 <= r[\"score_0_1\"] <= 1.0 for r in cache[\"results\"])\n",
    "\n",
    "# 2. 채점 근거(reasons)가 2개 이상인지 확인\n",
    "ok_reasons = all(len(r[\"reasons\"]) >= 2 for r in cache[\"results\"])\n",
    "\n",
    "# 3. 원본 텍스트에 금칙어가 없는지 확인\n",
    "ok_prof = all(profanity_hits(s[\"text\"]) == 0 for s in cache[\"samples\"])\n",
    "\n",
    "print(\"--- 검증 결과 ---\")\n",
    "print(f\"점수 범위 정상 (0~1): {ok_range}\")\n",
    "print(f\"최소 근거 개수 충족 (>=2): {ok_reasons}\")\n",
    "print(f\"금칙어 없음: {ok_prof}\")\n",
    "\n",
    "final_ok = ok_range and ok_reasons and ok_prof\n",
    "print(f\"\\n==> 최종 품질 검증: {'통과' if final_ok else '실패'}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO3O7s2UTAWPZ9/ncROdOM3",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
